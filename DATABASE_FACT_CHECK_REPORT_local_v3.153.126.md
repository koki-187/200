# データベース品質ファクトチェックレポート

**生成日時**: 2025-12-18T17:41:23.154Z
**バージョン**: v3.153.126
**対象環境**: LOCAL
**データベース**: real-estate-200units-db

---

## 📊 エグゼクティブサマリー

### 総合評価: ⚠️ **要改善（45/100点）**

| 評価項目 | スコア | 詳細 |
|---------|-------|------|
| データ正確性 | 5/30 | 低精度 |
| データ完全性 | 20/20 | 完全 |
| データ検証 | 5/20 | 一部検証 |
| データ鮮度 | 5/15 | 普通 |
| データ整合性 | 10/15 | 整合性あり |

---

## 📈 データ統計

### 全体統計
- **ハザードレコード総数**: 752件
- **データ品質テーブル数**: 3

### データ品質内訳

#### hazard_info
- **信頼度**: low
- **検証ステータス**: pending
- **レコード数**: 752
- **割合**: 100%


#### zoning_restrictions
- **信頼度**: low
- **検証ステータス**: pending
- **レコード数**: 56
- **割合**: 100%


#### geography_risks
- **信頼度**: low
- **検証ステータス**: pending
- **レコード数**: 38
- **割合**: 100%


### ハザードタイプ別分布
- **flood**: 188件
- **landslide**: 188件
- **liquefaction**: 188件
- **tsunami**: 188件

### リスクレベル別分布
- **high**: 199件
- **low**: 193件
- **medium**: 185件
- **none**: 175件

### 都道府県別分布
- **千葉県**: 168件
- **埼玉県**: 196件
- **東京都**: 212件
- **神奈川県**: 176件

---

## 🚨 検出された問題


### 1. hazard_infoテーブルに低品質データ存在 [CRITICAL]

**種類**: LOW_CONFIDENCE
**説明**: 752件のデータが confidence_level='low' です
**影響**: 実際のリスク評価と異なる可能性
**影響レコード数**: 752


### 2. zoning_restrictionsテーブルに低品質データ存在 [CRITICAL]

**種類**: LOW_CONFIDENCE
**説明**: 56件のデータが confidence_level='low' です
**影響**: 実際のリスク評価と異なる可能性
**影響レコード数**: 56


### 3. geography_risksテーブルに低品質データ存在 [CRITICAL]

**種類**: LOW_CONFIDENCE
**説明**: 38件のデータが confidence_level='low' です
**影響**: 実際のリスク評価と異なる可能性
**影響レコード数**: 38


### 4. hazard_infoテーブルの検証待ち [HIGH]

**種類**: PENDING_VERIFICATION
**説明**: 752件のデータが検証待ちです
**影響**: データの正確性が未確認
**影響レコード数**: 752


### 5. zoning_restrictionsテーブルの検証待ち [HIGH]

**種類**: PENDING_VERIFICATION
**説明**: 56件のデータが検証待ちです
**影響**: データの正確性が未確認
**影響レコード数**: 56


### 6. geography_risksテーブルの検証待ち [HIGH]

**種類**: PENDING_VERIFICATION
**説明**: 38件のデータが検証待ちです
**影響**: データの正確性が未確認
**影響レコード数**: 38


---

## 💡 推奨事項


### 1. 国交省APIからの正確なデータ取得 [優先度: CRITICAL]

**説明**: 現在のデータを国交省ハザードマップAPIから取得した正確なデータに置き換える
**推定工数**: 8-12時間

**実装ステップ**:
- 1. MLIT API Key設定（.dev.vars）
- 2. comprehensive-check APIの活用
- 3. データ収集スクリプト実行
- 4. マイグレーション適用
- 5. E2Eテスト実施


### 2. データ検証プロセスの実装 [優先度: HIGH]

**説明**: pending データに対してファクトチェックを実施
**推定工数**: 4-6時間

**実装ステップ**:
- 1. 複数データソース比較ロジック実装
- 2. データ矛盾検出アルゴリズム
- 3. 自動検証スクリプト作成
- 4. 手動確認フローの構築


---

## 🎯 次のアクション

### 最優先タスク

1. ⏳ 国交省APIからの正確なデータ取得実装
2. ⏳ データベース更新（サンプル → 正確なデータ）
3. ⏳ E2Eテスト再実施


### 推奨タスク
1. ⏳ データ品質ダッシュボード構築
2. ⏳ 自動ファクトチェックシステム実装
3. ⏳ データ異常検知アラート機能

---

## ⚠️ 重要な注意事項


**本番運用リスク**:
- データ品質スコアが50点未満です
- 正確なデータへの置換が推奨されます
- 融資判定の精度に影響する可能性があります

**本番運用前に必須**:
- 国交省APIからの正確なデータ取得
- ファクトチェック実施
- E2Eテスト合格


---

**レポート生成者**: AI Assistant (Database Fact Check System v3.153.126)
**生成スクリプト**: /home/user/webapp/scripts/fact-check-database-quality.cjs
**次回実行推奨**: データ更新後
